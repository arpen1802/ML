{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Recursive Algorithm of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(data):\n",
    "    # TODO Calculate the number of each label.\n",
    "    # Return a dict with the labels as keys, and\n",
    "    # their accurances as values\n",
    "    unique, counts = np.unique(data[:,-1], return_counts=True)\n",
    "    labels = dict(zip(unique, counts))\n",
    "    return labels\n",
    "\n",
    "def divide_data(data, feature_column, feature_val):\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    # TODO split the data into two parts by feature_column,\n",
    "    # where data1 contains all with value at feature column less than\n",
    "    # feature_value, and data2 contains all values larger that veature_val\n",
    "    data1 = data[data[:,feature_column] < feature_val]\n",
    "    data2 = data[data[:,feature_column] > feature_val]\n",
    "    return data1, data2\n",
    "\n",
    "def gini(data):\n",
    "    gini = 1\n",
    "    counts = value_counts(data)\n",
    "    for lbl in counts:\n",
    "        prob_lbl = counts[lbl] / len(data)\n",
    "        gini -= prob_lbl**2    \n",
    "    return gini\n",
    "\n",
    "def entropy(data):\n",
    "    #TODO calculate the entropy\n",
    "    sumUp = 0\n",
    "    for i in np.unique(data[:,-1]):\n",
    "        sumUp+=(len(data[data[:,-1]==i])/len(data[:,-1]))*np.log(len(data[data[:,-1]==i])/len(data[:,-1]))\n",
    "    entropy = -sumUp    \n",
    "    return entropy\n",
    "\n",
    "def square_loss(data):\n",
    "    y_pred = [np.mean(data[:, :-1])]*len(data)\n",
    "    y_true = data[:, -1:]\n",
    "    loss = loss = np.mean((y_true - y_pred)**2)\n",
    "    return loss\n",
    "\n",
    "class DecisionNode(object):\n",
    "    def __init__(self,\n",
    "                 column=None,\n",
    "                 value=None,\n",
    "                 false_branch=None,\n",
    "                 true_branch=None,\n",
    "                 current_results=None,\n",
    "                 is_leaf=False):\n",
    "        \"\"\"\n",
    "        column: column is the index of feature by wich data is splitted\n",
    "        value: value is column's value by which we filter data into splits\n",
    "        true_branch: boolean, if True, it is the true branch of it's parent\n",
    "        false_branch: boolean, if True, it is the false branch of it's parent\n",
    "        is_leaf: boolean, if True, node has no child\n",
    "        current_results: is value_counts(data) for data which reached this node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        self.false_branch = false_branch\n",
    "        self.true_branch = true_branch\n",
    "        self.current_results = current_results\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "def build_tree(data, current_depth=0, max_depth=4, criterion=gini, task=\"classification\"):\n",
    "    \"\"\"\n",
    "    Task can be classification or regression\n",
    "    Criterion is inpurity function to use\n",
    "    \"\"\"\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return DecisionNode(is_leaf=True)\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    \n",
    "    if len(value_counts(data)) == 1:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    \n",
    "    best_column = 0\n",
    "    best_value = 0\n",
    "    stop_splitting = False\n",
    "    criterion_parent = criterion(data)\n",
    "    best_criterion = criterion_parent\n",
    "    data_X = data[:,:-1]\n",
    "    \n",
    "    for col in range(data_X.shape[1]):\n",
    "        for s_val in data_X[:,col]:\n",
    "            split_neg, split_pos = divide_data(data, col, s_val)\n",
    "            # This line was needed for regression task, without it error was thrown\n",
    "            if len(split_neg)==0 or len(split_pos)==0:\n",
    "                continue\n",
    "            best_criterion_tmp = (len(split_neg)/len(data))*criterion(split_neg) + (len(split_pos)/len(data))*criterion(split_pos)\n",
    "            if best_criterion_tmp < best_criterion:\n",
    "                best_criterion = best_criterion_tmp\n",
    "                best_column = col\n",
    "                best_value = s_val\n",
    "               \n",
    "    split_neg, split_pos = divide_data(data, best_column, best_value)\n",
    "    \n",
    "    if (best_criterion == criterion_parent):\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    \n",
    "    else:\n",
    "        return DecisionNode(column=best_column,\n",
    "                            value=best_value,\n",
    "                            current_results=value_counts(data),\n",
    "                            false_branch=build_tree(split_neg, current_depth+1, max_depth),\n",
    "                            true_branch=build_tree(split_pos, current_depth+1, max_depth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, max_tree_depth=4, criterion=\"gini\", task=\"classification\"):\n",
    "        self.max_depth = max_tree_depth\n",
    "        self.tree = None\n",
    "        self.task = task\n",
    "        self.criterion = gini\n",
    "        \n",
    "        if criterion == \"entropy\":\n",
    "            self.criterion = entropy\n",
    "        if criterion == \"square_loss\":\n",
    "            self.criterion = square_loss\n",
    "        if(task==\"regression\" and criterion!=\"square_loss\"):\n",
    "            raise ValueError(\"For Regression task please use square_loss criterion\")\n",
    "        if(task==\"classification\" and criterion==\"square_loss\"):\n",
    "            raise ValueError(\"For Classification Task Please use gini or entrophy criterion\")\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # build data\n",
    "        data = np.concatenate((X, y.reshape(-1,1)),axis = 1)\n",
    "        self.tree = build_tree(data,\n",
    "                               task=self.task,\n",
    "                               max_depth=self.max_depth, \n",
    "                               criterion=self.criterion)\n",
    "        \n",
    "    def predict(self, X):\n",
    "        Y = []\n",
    "\n",
    "        for i in X:\n",
    "            tree = self.tree\n",
    "            while tree.is_leaf==False:   \n",
    "                if(i[tree.column] < tree.value):   \n",
    "                    tree = tree.false_branch\n",
    "                else:\n",
    "                    tree = tree.true_branch\n",
    "            else:\n",
    "                if(self.task =='classification'):\n",
    "                    Y.append(max(tree.current_results,key=tree.current_results.get))\n",
    "                else:\n",
    "                    paires=[]\n",
    "                    for pred,amount in tree.current_results.items():\n",
    "                        paires.extend([pred]*int(amount))\n",
    "                    pred = sum(paires)/len(paires)\n",
    "                    Y.append(pred)\n",
    "                \n",
    "        # TODO get labels       \n",
    "        return np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Results on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "boston = load_boston(return_X_y=True) \n",
    "boston = np.concatenate((boston[0], boston[1].reshape(-1,1)),axis = 1)\n",
    "iris = load_iris(return_X_y=True)\n",
    "iris = np.concatenate((iris[0], iris[1].reshape(-1,1)),axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris[:,:-1], iris[:,-1], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree(criterion='gini',task=\"classification\",max_tree_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boston[:,:-1], boston[:,-1], test_size=0.33, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DecisionTree(criterion=\"square_loss\",task=\"regression\",max_tree_depth=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "88.35196107784431"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_squared_error(y_test, model2.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It still left unknown what was the difference between our codes :D "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
