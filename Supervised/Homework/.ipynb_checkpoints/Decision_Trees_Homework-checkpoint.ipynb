{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Recursive Algorithm of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(data):\n",
    "    # TODO Calculate the number of each label.\n",
    "    # Return a dict with the labels as keys, and\n",
    "    # their accurances as values\n",
    "    unique, counts = np.unique(data[:,-1], return_counts=True)\n",
    "    labels = dict(zip(unique, counts))\n",
    "    return labels\n",
    "\n",
    "def divide_data(data, feature_column, feature_val):\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    # TODO split the data into two parts by feature_column,\n",
    "    # where data1 contains all with value at feature column less than\n",
    "    # feature_value, and data2 contains all values larger that veature_val\n",
    "    data1 = data[data[:,feature_column] < feature_val]\n",
    "    data2 = data[data[:,feature_column] >= feature_val]\n",
    "    return data1, data2\n",
    "\n",
    "def gini(data):\n",
    "    #TODO calculate the gini\n",
    "    sumUp = 0\n",
    "    for i in np.unique(data[:,-1]):\n",
    "        sumUp+=(len(data[data[:,-1]==i])/len(data[:,-1]))**2\n",
    "    gini = 1 - sumUp      \n",
    "    return gini\n",
    "\n",
    "def entropy(data):\n",
    "    #TODO calculate the entropy\n",
    "    sumUp = 0\n",
    "    for i in np.unique(data[:,-1]):\n",
    "        sumUp+=(len(data[data[:,-1]==i])/len(data[:,-1]))*np.log(len(data[data[:,-1]==i])/len(data[:,-1]))\n",
    "    entropy = -sumUp    \n",
    "    return entropy\n",
    "\n",
    "def square_loss(data):\n",
    "    #TODO calculate the loss\n",
    "    loss = 0\n",
    "    if(len(data)!=0):\n",
    "        for i in data[:,-1]:\n",
    "            y_pred = np.sum(data[:,-1])/len(data[:,-1])\n",
    "            loss+=(i-y_pred)**2\n",
    "        loss = loss/len(data[:,-1])\n",
    "    else:\n",
    "        loss = 0\n",
    "    return loss\n",
    "\n",
    "class DecisionNode(object):\n",
    "    def __init__(self,\n",
    "                 column=None,\n",
    "                 value=None,\n",
    "                 false_branch=None,\n",
    "                 true_branch=None,\n",
    "                 current_results=None,\n",
    "                 is_leaf=False):\n",
    "        \"\"\"\n",
    "        column: column is the index of feature by wich data is splitted\n",
    "        value: value is column's value by which we filter data into splits\n",
    "        true_branch: boolean, if True, it is the true branch of it's parent\n",
    "        false_branch: boolean, if True, it is the false branch of it's parent\n",
    "        is_leaf: boolean, if True, node has no child\n",
    "        current_results: is value_counts(data) for data which reached this node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        self.false_branch = false_branch\n",
    "        self.true_branch = true_branch\n",
    "        self.current_results = current_results\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "def build_tree(data, current_depth=0, max_depth=4, criterion=gini, task=\"classification\"):\n",
    "    \"\"\"\n",
    "    Task can be classification or regression\n",
    "    Criterion is inpurity function to use\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    if len(data) == 0:\n",
    "        return DecisionNode(is_leaf=True)\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    \n",
    "    if len(value_counts(data)) == 1:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "\n",
    "    # TODO, calculate best split \n",
    "    # split_pos = []\n",
    "    # split_neg = []\n",
    "    info_gain = 0\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            split_neg,split_pos = divide_data(data,j,i)\n",
    "            temp = criterion(data) - (split_neg.shape[0]/data.shape[0])*criterion(split_neg) - (split_pos.shape[0]/data.shape[0])*criterion(split_pos)\n",
    "            if(temp>info_gain):\n",
    "                info_gain = temp\n",
    "                best_column = j\n",
    "                best_value = i\n",
    "                \n",
    "    \n",
    "    # if we cannot improve by splitting:  \n",
    "    split_neg,split_pos = divide_data(data,best_column,best_value)\n",
    "    if(criterion(data)==0):\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    else:\n",
    "        return DecisionNode(column=best_column,\n",
    "                            value=best_value,\n",
    "                            current_results=value_counts(data),\n",
    "                            false_branch=build_tree(split_neg, current_depth+1, max_depth,criterion=criterion),\n",
    "                            true_branch=build_tree(split_pos, current_depth+1, max_depth,criterion=criterion))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, max_tree_depth=4, criterion=\"gini\", task=\"classification\"):\n",
    "        self.max_depth = max_tree_depth\n",
    "        self.tree = None\n",
    "        self.task = task\n",
    "        \n",
    "        self.criterion = gini\n",
    "        if criterion == \"entropy\":\n",
    "            self.criterion = entropy\n",
    "        if criterion == \"square_loss\":\n",
    "            self.criterion = square_loss\n",
    "        if(task==\"regression\" and criterion!=\"square_loss\"):\n",
    "            raise ValueError(\"For Regression task please use square_loss criterion\")\n",
    "        if(task==\"classification\" and criterion==\"square_loss\"):\n",
    "            raise ValueError(\"For Classification Task Please use gini or entrophy criterion\")\n",
    "    \n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # build data\n",
    "        data = np.concatenate((X, y.reshape(-1,1)),axis = 1)\n",
    "        self.tree = build_tree(data,\n",
    "                               task=self.task,\n",
    "                               max_depth=self.max_depth, \n",
    "                               criterion=self.criterion)\n",
    "    def predict(self, X):\n",
    "        Y = []\n",
    "        \n",
    "        for i in X:\n",
    "            tree = self.tree\n",
    "            while tree.is_leaf==False:   \n",
    "                if(i[tree.column-1] < tree.value):   \n",
    "                    tree = tree.false_branch\n",
    "                else:\n",
    "                    tree = tree.true_branch\n",
    "            else:\n",
    "                Y.append(list(tree.current_results.keys())[0])\n",
    "        # TODO get labels       \n",
    "        return np.array(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Results on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "boston = load_boston(return_X_y=True) \n",
    "boston = np.concatenate((boston[0], boston[1].reshape(-1,1)),axis = 1)\n",
    "iris = load_iris(return_X_y=True)\n",
    "iris = np.concatenate((iris[0], iris[1].reshape(-1,1)),axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris[:,:-1], iris[:,-1], test_size=0.33, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree(criterion='gini',task=\"classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(boston[:,:-1], boston[:,-1], test_size=0.33, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = DecisionTree(criterion=\"square_loss\",task=\"regression\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20. ,  9.5,  9.5,  9.5,  5. ,  5. , 12.5,  5. , 24. , 30.1,  5. ,\n",
       "        5. ,  5. , 12.5, 15. ,  5. , 17. , 12.5, 20. ,  5. ,  5. , 12.5,\n",
       "        9.5, 12.5, 17. ,  9.5,  9.5, 20. , 22. ,  5. ,  9.5, 27.1,  5. ,\n",
       "       24. ,  5. ,  5. ,  5. , 15. ,  5. ,  9.5,  5. , 12.5,  5. ,  9.5,\n",
       "        5. ,  5. ,  5. , 17. ,  5. ,  9.5, 12.5,  9.5, 17. ,  5. , 12.5,\n",
       "       15. ,  5. , 20. ,  9.5, 12.5, 20. ,  5. ,  5. ,  9.5, 12.5,  9.5,\n",
       "        9.5,  5. ,  5. , 24. ,  9.5, 24. , 22. ,  5. , 12.5, 17. , 30.1,\n",
       "       17. ,  5. ,  9.5, 12.5, 12.5,  9.5, 12.5,  5. , 12.5, 27.1,  5. ,\n",
       "        5. ,  9.5, 15. , 15. ,  9.5, 22. , 24. ,  9.5,  5. ,  9.5,  5. ,\n",
       "       12.5, 12.5, 20. ,  5. ,  5. , 12.5,  9.5, 20. ,  5. , 33. ,  5. ,\n",
       "       12.5,  5. ,  9.5,  9.5,  9.5, 15. ,  9.5,  5. ,  5. ,  9.5,  5. ,\n",
       "        9.5,  5. , 20. ,  9.5, 17. ,  5. ,  5. ,  9.5, 17. , 12.5,  5. ,\n",
       "       17. , 24. ,  9.5, 24. , 17. ,  9.5, 17. , 20. , 12.5,  9.5, 22. ,\n",
       "       17. , 15. , 12.5,  5. ,  5. ,  5. ,  5. ,  5. ,  9.5,  9.5, 12.5,\n",
       "       12.5,  5. , 17. ,  5. ,  5. ,  5. , 15. ,  9.5,  5. ,  9.5,  9.5,\n",
       "        5. ,  5. ])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
