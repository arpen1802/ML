{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Recursive Algorithm of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(data):\n",
    "    # TODO Calculate the number of each label.\n",
    "    # Return a dict with the labels as keys, and\n",
    "    # their accurances as values\n",
    "    unique, counts = np.unique(data[:,-1], return_counts=True)\n",
    "    labels = dict(zip(unique, counts))\n",
    "    return labels\n",
    "\n",
    "def divide_data(data, feature_column, feature_val):\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    # TODO split the data into two parts by feature_column,\n",
    "    # where data1 contains all with value at feature column less than\n",
    "    # feature_value, and data2 contains all values larger that veature_val\n",
    "    data1 = data[data[:,feature_column] < feature_val]\n",
    "    data2 = data[data[:,feature_column] >= feature_val]\n",
    "    return data1, data2\n",
    "\n",
    "def gini(data):\n",
    "    #TODO calculate the gini\n",
    "    sumUp = 0\n",
    "    for i in np.unique(data[:,-1]):\n",
    "        sumUp+=(len(data[data[:,-1]==i])/len(data[:,-1]))**2\n",
    "    gini = 1 - sumUp      \n",
    "    return gini\n",
    "\n",
    "def entropy(data):\n",
    "    #TODO calculate the entropy\n",
    "    sumUp = 0\n",
    "    for i in np.unique(data[:,-1]):\n",
    "        sumUp+=(len(data[data[:,-1]==i])/len(data[:,-1]))*np.log(len(data[data[:,-1]==i])/len(data[:,-1]))\n",
    "    entropy = -sumUp    \n",
    "    return entropy\n",
    "\n",
    "def square_loss(data):\n",
    "    #TODO calculate the loss\n",
    "    for i in data[:,-1]:\n",
    "        y_pred = np.sum(data[:,-1])/len(data[:,-1])\n",
    "        loss+=(i-y_pred)**2\n",
    "    loss = loss/len(data[:,-1])\n",
    "    return loss\n",
    "\n",
    "class DecisionNode(object):\n",
    "    def __init__(self,\n",
    "                 column=None,\n",
    "                 value=None,\n",
    "                 false_branch=None,\n",
    "                 true_branch=None,\n",
    "                 current_results=None,\n",
    "                 is_leaf=False):\n",
    "        \"\"\"\n",
    "        column: column is the index of feature by wich data is splitted\n",
    "        value: value is column's value by which we filter data into splits\n",
    "        true_branch: boolean, if True, it is the true branch of it's parent\n",
    "        false_branch: boolean, if True, it is the false branch of it's parent\n",
    "        is_leaf: boolean, if True, node has no child\n",
    "        current_results: is value_counts(data) for data which reached this node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        self.false_branch = false_branch\n",
    "        self.true_branch = true_branch\n",
    "        self.current_results = current_results\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "def build_tree(data, current_depth=0, max_depth=4, criterion=gini, task=\"classification\"):\n",
    "    \"\"\"\n",
    "    Task can be classification or regression\n",
    "    Criterion is inpurity function to use\n",
    "    \"\"\"\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return DecisionNode(is_leaf=True)\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    \n",
    "    if len(value_counts(data)) == 1:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "\n",
    "    # TODO, calculate best split \n",
    "    # split_pos = []\n",
    "    # split_neg = []\n",
    "    info_gain = 0\n",
    "   \n",
    "    \n",
    "    for i in range(iris.shape[0]):\n",
    "        for j in range(iris.shape[1]):\n",
    "            split_neg,split_pos = divide_data(data,j,i)\n",
    "            temp = criterion(data) - (split_neg.shape[0]/data.shape[0])*criterion(split_neg) - (split_pos.shape[0]/data.shape[0])*criterion(split_pos)\n",
    "            if(temp>info_gain):\n",
    "                info_gain = temp\n",
    "                best_column = j\n",
    "                best_value = i\n",
    "    \n",
    "    # if we cannot improve by splitting:           \n",
    "    if(criterion(data)==0):\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    else:\n",
    "        return DecisionNode(column=best_column,\n",
    "                            value=best_value,\n",
    "                            current_results=value_counts(data),\n",
    "                            false_branch=build_tree(split_neg, current_depth+1, max_depth),\n",
    "                            true_branch=build_tree(split_pos, current_depth+1, max_depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, max_tree_depth=4, criterion=\"gini\", task=\"classification\"):\n",
    "        self.max_depth = max_tree_depth\n",
    "        self.tree = None\n",
    "        self.task = task\n",
    "        \n",
    "        self.criterion = gini\n",
    "        if criterion == \"entropy\":\n",
    "            self.criterion = entropy\n",
    "        if criterion == \"square_loss\":\n",
    "            self.criterion = square_loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # build data\n",
    "        data = np.concatenate((X, y.reshape(-1,1)),axis = 1)\n",
    "        self.tree = build_tree(data,\n",
    "                               task=self.task,\n",
    "                               max_depth=self.max_depth, \n",
    "                               criterion=self.criterion)\n",
    "    def predict(self, X):\n",
    "        y = []\n",
    "        node = self.tree\n",
    "        if(node.is_leaf==True):\n",
    "            \n",
    "        else:\n",
    "            \n",
    "                \n",
    "            \n",
    "        Y = self.tree.false_branch\n",
    "        # TODO get labels       \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Results on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston(return_X_y=True) \n",
    "boston = np.concatenate((boston[0], boston[1].reshape(-1,1)),axis = 1)\n",
    "iris = load_iris(return_X_y=True)\n",
    "iris = np.concatenate((iris[0], iris[1].reshape(-1,1)),axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris[:,:-1], iris[:,-1], test_size=0.33, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_test).false_branch.false_branch.false_branch.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "labels = dict(zip(unique, counts))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
