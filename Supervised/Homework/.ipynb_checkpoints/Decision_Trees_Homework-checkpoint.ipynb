{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implement the Recursive Algorithm of Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "def value_counts(data):\n",
    "    # TODO Calculate the number of each label.\n",
    "    # Return a dict with the labels as keys, and\n",
    "    # their accurances as values\n",
    "    unique, counts = np.unique(data[:,-1], return_counts=True)\n",
    "    labels = dict(zip(unique, counts))\n",
    "    return labels\n",
    "\n",
    "def divide_data(data, feature_column, feature_val):\n",
    "    data1 = []\n",
    "    data2 = []\n",
    "    # TODO split the data into two parts by feature_column,\n",
    "    # where data1 contains all with value at feature column less than\n",
    "    # feature_value, and data2 contains all values larger that veature_val\n",
    "    data1 = data[data[:,feature_column] < feature_val]\n",
    "    data2 = data[data[:,feature_column] >= feature_val]\n",
    "    return data1, data2\n",
    "\n",
    "def gini(data):\n",
    "    #TODO calculate the gini\n",
    "    sumUp = 0\n",
    "    for i in np.unique(data[:,-1]):\n",
    "        sumUp+=(len(data[data[:,-1]==i])/len(data[:,-1]))**2\n",
    "    gini = 1 - sumUp      \n",
    "    return gini\n",
    "\n",
    "def entropy(data):\n",
    "    #TODO calculate the entropy\n",
    "    sumUp = 0\n",
    "    for i in np.unique(data[:,-1]):\n",
    "        sumUp+=(len(data[data[:,-1]==i])/len(data[:,-1]))*np.log(len(data[data[:,-1]==i])/len(data[:,-1]))\n",
    "    entropy = -sumUp    \n",
    "    return entropy\n",
    "\n",
    "def square_loss(data):\n",
    "    #TODO calculate the loss\n",
    "    for i in data[:,-1]:\n",
    "        y_pred = np.sum(data[:,-1])/len(data[:,-1])\n",
    "        loss+=(i-y_pred)**2\n",
    "    loss = loss/len(data[:,-1])\n",
    "    return loss\n",
    "\n",
    "class DecisionNode(object):\n",
    "    def __init__(self,\n",
    "                 column=None,\n",
    "                 value=None,\n",
    "                 false_branch=None,\n",
    "                 true_branch=None,\n",
    "                 current_results=None,\n",
    "                 is_leaf=False):\n",
    "        \"\"\"\n",
    "        column: column is the index of feature by wich data is splitted\n",
    "        value: value is column's value by which we filter data into splits\n",
    "        true_branch: boolean, if True, it is the true branch of it's parent\n",
    "        false_branch: boolean, if True, it is the false branch of it's parent\n",
    "        is_leaf: boolean, if True, node has no child\n",
    "        current_results: is value_counts(data) for data which reached this node\n",
    "        \"\"\"\n",
    "        \n",
    "        self.column = column\n",
    "        self.value = value\n",
    "        self.false_branch = false_branch\n",
    "        self.true_branch = true_branch\n",
    "        self.current_results = current_results\n",
    "        self.is_leaf = is_leaf\n",
    "\n",
    "def build_tree(data, current_depth=0, max_depth=4, criterion=gini, task=\"classification\"):\n",
    "    \"\"\"\n",
    "    Task can be classification or regression\n",
    "    Criterion is inpurity function to use\n",
    "    \"\"\"\n",
    "\n",
    "    if len(data) == 0:\n",
    "        return DecisionNode(is_leaf=True)\n",
    "\n",
    "    if current_depth == max_depth:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    \n",
    "    if len(value_counts(data)) == 1:\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "\n",
    "    # TODO, calculate best split \n",
    "    # split_pos = []\n",
    "    # split_neg = []\n",
    "    info_gain = 0\n",
    "\n",
    "    for i in range(data.shape[0]):\n",
    "        for j in range(data.shape[1]):\n",
    "            split_neg,split_pos = divide_data(data,j,i)\n",
    "            temp = criterion(data) - (split_neg.shape[0]/data.shape[0])*criterion(split_neg) - (split_pos.shape[0]/data.shape[0])*criterion(split_pos)\n",
    "            if(temp>info_gain):\n",
    "                info_gain = temp\n",
    "                best_column = j\n",
    "                best_value = i\n",
    "    \n",
    "    # if we cannot improve by splitting:           \n",
    "    if(criterion(data)==0):\n",
    "        return DecisionNode(current_results=value_counts(data), is_leaf=True)\n",
    "    else:\n",
    "        return DecisionNode(column=best_column,\n",
    "                            value=best_value,\n",
    "                            current_results=value_counts(data),\n",
    "                            false_branch=build_tree(split_neg, current_depth+1, max_depth),\n",
    "                            true_branch=build_tree(split_pos, current_depth+1, max_depth))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree(object):\n",
    "    def __init__(self, max_tree_depth=4, criterion=\"gini\", task=\"classification\"):\n",
    "        self.max_depth = max_tree_depth\n",
    "        self.tree = None\n",
    "        self.task = task\n",
    "        \n",
    "        self.criterion = gini\n",
    "        if criterion == \"entropy\":\n",
    "            self.criterion = entropy\n",
    "        if criterion == \"square_loss\":\n",
    "            self.criterion = square_loss\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # build data\n",
    "        data = np.concatenate((X, y.reshape(-1,1)),axis = 1)\n",
    "        self.tree = build_tree(data,\n",
    "                               task=self.task,\n",
    "                               max_depth=self.max_depth, \n",
    "                               criterion=self.criterion)\n",
    "    def predict(self, X):\n",
    "        Y = []\n",
    "        \n",
    "        for i in X:\n",
    "            tree = self.tree\n",
    "            while tree.is_leaf==False:   \n",
    "                if(i[tree.column] < tree.value):   \n",
    "                    tree = tree.false_branch\n",
    "                else:\n",
    "                    tree = tree.true_branch\n",
    "            else:\n",
    "                Y.append(tree.current_results)\n",
    "        # TODO get labels       \n",
    "        return Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perform Results on Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_boston\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "boston = load_boston(return_X_y=True) \n",
    "boston = np.concatenate((boston[0], boston[1].reshape(-1,1)),axis = 1)\n",
    "iris = load_iris(return_X_y=True)\n",
    "iris = np.concatenate((iris[0], iris[1].reshape(-1,1)),axis = 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(iris[:,:-1], iris[:,-1], test_size=0.33, random_state=58)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecisionTree()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "ename": "UnboundLocalError",
     "evalue": "local variable 'info_gain' referenced before assignment",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-190-b7a8c64777c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-186-33e3908c2ae3>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     17\u001b[0m                                \u001b[0mtask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                \u001b[0mmax_depth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_depth\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m                                criterion=self.criterion)\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mY\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-185-5730db5801cf>\u001b[0m in \u001b[0;36mbuild_tree\u001b[0;34m(data, current_depth, max_depth, criterion, task)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;31m# split_pos = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# split_neg = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minfo_gain\u001b[0m\u001b[0;34m!=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m         \u001b[0minfo_gain\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'info_gain' referenced before assignment"
     ]
    }
   ],
   "source": [
    "model.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'is_leaf'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-184-decd67bbf386>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-179-33e3908c2ae3>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_leaf\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m                 \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumn\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                     \u001b[0mtree\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfalse_branch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'is_leaf'"
     ]
    }
   ],
   "source": [
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
